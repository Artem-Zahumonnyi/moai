name: CI/CD Pipeline with Performance Testing

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  build-and-test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Build Docker image
      run: |
        docker build -t moai-app:${{ github.sha }} -f app.dockerfile .

    # Added cache for Trivy
    - name: Cache Trivy vulnerability database
      uses: actions/cache@v3
      with:
        path: .trivycache/
        key: ${{ runner.os }}-trivy-${{ hashFiles('**/Dockerfile') }}
        restore-keys: |
          ${{ runner.os }}-trivy-

    # Updated Trivy scan with retry mechanism and cache
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        image-ref: 'moai-app:${{ github.sha }}'
        format: 'table'
        exit-code: '1'
        ignore-unfixed: true
        vuln-type: 'os,library'
        severity: 'CRITICAL,HIGH'
        cache-dir: .trivycache/
        timeout: '1m'
        retries: 5
        wait-time: '30s'

    - name: Set up JMeter
      run: |
        wget https://downloads.apache.org/jmeter/binaries/apache-jmeter-5.6.3.tgz
        tar -xzf apache-jmeter-5.6.3.tgz
        
    - name: Start application for testing
      run: |
        docker run -d -p 8080:8080 moai-app:${{ github.sha }}
        sleep 10  # Wait for application to start

    - name: Create JMeter test plan
      run: |
        cat << EOF > performance-test.jmx
        <?xml version="1.0" encoding="UTF-8"?>
        <jmeterTestPlan version="1.2" properties="5.0">
          <hashTree>
            <TestPlan guiclass="TestPlanGui" testclass="TestPlan" testname="Moai App Test Plan">
              <elementProp name="TestPlan.user_defined_variables" elementType="Arguments">
                <collectionProp name="Arguments.arguments"/>
              </elementProp>
              <boolProp name="TestPlan.functional_mode">false</boolProp>
            </TestPlan>
            <hashTree>
              <ThreadGroup guiclass="ThreadGroupGui" testclass="ThreadGroup" testname="Thread Group">
                <elementProp name="ThreadGroup.main_controller" elementType="LoopController">
                  <boolProp name="LoopController.continue_forever">false</boolProp>
                  <intProp name="LoopController.loops">3</intProp>
                </elementProp>
                <stringProp name="ThreadGroup.num_threads">5</stringProp>
                <stringProp name="ThreadGroup.ramp_time">1</stringProp>
                <boolProp name="ThreadGroup.scheduler">false</boolProp>
                <stringProp name="ThreadGroup.duration"></stringProp>
                <stringProp name="ThreadGroup.delay"></stringProp>
              </ThreadGroup>
              <hashTree>
                <HTTPSamplerProxy guiclass="HttpTestSampleGui" testclass="HTTPSamplerProxy">
                  <elementProp name="HTTPsampler.Arguments" elementType="Arguments">
                    <collectionProp name="Arguments.arguments"/>
                  </elementProp>
                  <stringProp name="HTTPSampler.domain">localhost</stringProp>
                  <stringProp name="HTTPSampler.port">8080</stringProp>
                  <stringProp name="HTTPSampler.path">/</stringProp>
                  <stringProp name="HTTPSampler.method">GET</stringProp>
                </HTTPSamplerProxy>
                <hashTree/>
                <ResultCollector guiclass="ViewResultsFullVisualizer" testclass="ResultCollector" testname="Results">
                  <boolProp name="ResultCollector.error_logging">false</boolProp>
                  <objProp>
                    <name>saveConfig</name>
                    <value class="SampleSaveConfiguration">
                      <time>true</time>
                      <latency>true</latency>
                      <timestamp>true</timestamp>
                      <success>true</success>
                      <label>true</label>
                      <code>true</code>
                      <message>true</message>
                      <threadName>true</threadName>
                      <dataType>true</dataType>
                      <encoding>false</encoding>
                      <assertions>true</assertions>
                      <subresults>true</subresults>
                      <responseData>false</responseData>
                      <samplerData>false</samplerData>
                      <xml>false</xml>
                      <fieldNames>true</fieldNames>
                      <responseHeaders>false</responseHeaders>
                      <requestHeaders>false</requestHeaders>
                      <responseDataOnError>false</responseDataOnError>
                      <saveAssertionResultsFailureMessage>true</saveAssertionResultsFailureMessage>
                      <assertionsResultsToSave>0</assertionsResultsToSave>
                      <bytes>true</bytes>
                      <sentBytes>true</sentBytes>
                      <url>true</url>
                      <threadCounts>true</threadCounts>
                      <sampleCount>true</sampleCount>
                    </value>
                  </objProp>
                  <stringProp name="filename">test-results.jtl</stringProp>
                </ResultCollector>
                <hashTree/>
              </hashTree>
            </hashTree>
          </hashTree>
        </jmeterTestPlan>
        EOF

    - name: Run performance tests
      run: |
        apache-jmeter-5.6.3/bin/jmeter -n -t performance-test.jmx -l test-results.jtl

    - name: Generate performance report
      run: |
        echo "Performance Test Results" > performance-report.txt
        cat test-results.jtl >> performance-report.txt

    - name: Upload performance results
      uses: actions/upload-artifact@v3
      with:
        name: performance-results
        path: performance-report.txt
        retention-days: 5
